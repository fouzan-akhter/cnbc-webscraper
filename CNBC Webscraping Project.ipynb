{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e065baea",
   "metadata": {},
   "source": [
    "# CNBC Webscraping Project\n",
    "\n",
    "Author: Muhammad Fouzan Akhter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42acbaf6",
   "metadata": {},
   "source": [
    "The code for a web scraping project that targets CNBC is shown below. Underscoring the importance of following website privacy policies is crucial for any online scraping project. It is imperative to highlight that this project is scraping entirely publicly accessible data from Yahoo Finance while adhering to the platform's privacy standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing relevant packages:\n",
    "!pip install selenium\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507ec719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant libraries:\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41817ed3",
   "metadata": {},
   "source": [
    "**This Project is coded in Jupyter Notebook Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56172a65",
   "metadata": {},
   "source": [
    "If  ' Max Try Exceeded: Reconnection Error '  occurs, perform a DNS flush by entering the following command in your terminal or command prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d425fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the following command on terminal to flush DNS if Max Try Exceeded: Reconnection Error occurs:\n",
    "#ipconfig /flushdns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d29e8e",
   "metadata": {},
   "source": [
    "The following loops retrieve information from the HTML file, including each article's title, author, content type, date, content, and link. Prior to running the code, make sure the internet is active. Included for effective time management during code execution is a tqdm loadbar. A pandas dataframe will hold all of the extracted data. The `max_links_to_collect` informs the code of how many articles to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.cnbc.com/finance/'\n",
    "max_links_to_collect = 40\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "collected_links = set()\n",
    "while len(collected_links) < max_links_to_collect:\n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        article_links = [a['href'] for a in soup.find_all('a', class_='Card-title')]\n",
    "\n",
    "        for link in article_links:\n",
    "            collected_links.add(link)\n",
    "            if len(collected_links) >= max_links_to_collect:\n",
    "                break\n",
    "        load_more_button = driver.find_element(By.CLASS_NAME, 'LoadMoreButton-loadMore')\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        break\n",
    "driver.quit()\n",
    "dfs = []\n",
    "with tqdm(total=len(collected_links), desc=\"Scraping Articles\") as pbar_articles:\n",
    "    for link in collected_links:\n",
    "        response = requests.get(link)\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                article_name = soup.find('h1', class_='ArticleHeader-headline')\n",
    "                article_name = article_name.text.strip() if article_name else None\n",
    "                author = soup.find('a', class_='Author-authorName')\n",
    "                author = author.text.strip() if author else None\n",
    "                content_type = soup.find('a', class_='ArticleHeader-eyebrow')\n",
    "                content_type = content_type.text.strip() if content_type else None\n",
    "                date_time = soup.find('time', {'itemprop': 'datePublished'})\n",
    "                date_time = date_time.text.strip() if date_time else None\n",
    "                content_elements = soup.find('div', class_='ArticleBody-articleBody')\n",
    "                content = ' '.join(element.text.strip() for element in content_elements.find_all(['p', 'h2']))\n",
    "                details = {\n",
    "                    'Article Name': article_name,\n",
    "                    'Author': author,\n",
    "                    'Content Type': content_type,\n",
    "                    'Date Time': date_time,\n",
    "                    'Content': content,\n",
    "                    'Link': link,\n",
    "                }\n",
    "                dfs.append(pd.DataFrame([details]))\n",
    "                pbar_articles.update(1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping article '{link}': {e}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Error: Unable to fetch content. Status code {response.status_code}\")\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a2464",
   "metadata": {},
   "source": [
    "**Viewing Scraped Data in Python Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying scraped data in python environment:\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2bf35",
   "metadata": {},
   "source": [
    "**------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
